{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge - Boston House Prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and load the dataset\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([151.,  75., 141., 206., 135.,  97., 138.,  63., 110., 310., 101.,\n",
       "        69., 179., 185., 118., 171., 166., 144., 168.,  68.,  49., 245.,\n",
       "       184., 202., 137.,  85., 131., 283., 129.,  59., 341.,  87.,  65.,\n",
       "       102., 265., 276., 252.,  90., 100.,  55.,  61.,  92., 259.,  53.,\n",
       "       190., 142., 155., 225., 104., 182., 128.,  52.,  37., 170.,  71.,\n",
       "       163., 150., 160., 178.,  48., 270., 111.,  42., 200., 113., 143.,\n",
       "        51., 210., 134.,  98., 164.,  96., 162., 279.,  83., 302., 198.,\n",
       "        95., 232.,  81., 246., 297., 258., 229., 275., 281., 173., 180.,\n",
       "        84., 121., 161.,  99., 109., 115., 268., 274., 158., 107., 103.,\n",
       "       272., 280., 336., 317., 235.,  60., 174., 126., 288.,  88., 292.,\n",
       "       197., 186.,  25., 195., 217., 172., 214.,  70., 220., 152.,  47.,\n",
       "        74., 295., 127., 237.,  64.,  79.,  91., 116.,  86., 122.,  72.,\n",
       "        39., 196., 222., 277.,  77., 191.,  73., 263., 248., 296.,  78.,\n",
       "        93., 208., 108., 154., 124.,  67., 257., 262., 177., 187., 125.,\n",
       "       215., 303., 243., 153., 346.,  89.,  50., 308., 145.,  45., 264.,\n",
       "       241.,  66.,  94., 230., 181., 156., 233., 219.,  80., 332.,  31.,\n",
       "       236., 253.,  44., 114., 147., 242., 249., 192., 244., 199., 306.,\n",
       "       216., 139., 148.,  54., 221., 311., 321.,  58., 123., 167., 140.,\n",
       "        40., 132., 201., 273.,  43., 175., 293., 189., 209., 136., 261.,\n",
       "       146., 212., 120., 183.,  57.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes = load_diabetes(as_frame=True)\n",
    "target = diabetes.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6'], dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = diabetes.data\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019907</td>\n",
       "      <td>-0.017646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068332</td>\n",
       "      <td>-0.092204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005670</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002861</td>\n",
       "      <td>-0.025930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022688</td>\n",
       "      <td>-0.009362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031988</td>\n",
       "      <td>-0.046641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age       sex       bmi        bp        s1        s2        s3  \\\n",
       "0  0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1 -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2  0.085299  0.050680  0.044451 -0.005670 -0.045599 -0.034194 -0.032356   \n",
       "3 -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4  0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "\n",
       "         s4        s5        s6  \n",
       "0 -0.002592  0.019907 -0.017646  \n",
       "1 -0.039493 -0.068332 -0.092204  \n",
       "2 -0.002592  0.002861 -0.025930  \n",
       "3  0.034309  0.022688 -0.009362  \n",
       "4 -0.002592 -0.031988 -0.046641  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Have a look at the data\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_815048/3888310420.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.sex = data.sex.apply(lambda x: 1 if x>0 else 0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>1</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019907</td>\n",
       "      <td>-0.017646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068332</td>\n",
       "      <td>-0.092204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>1</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005670</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002861</td>\n",
       "      <td>-0.025930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022688</td>\n",
       "      <td>-0.009362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031988</td>\n",
       "      <td>-0.046641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  sex       bmi        bp        s1        s2        s3        s4  \\\n",
       "0  0.038076    1  0.061696  0.021872 -0.044223 -0.034821 -0.043401 -0.002592   \n",
       "1 -0.001882    0 -0.051474 -0.026328 -0.008449 -0.019163  0.074412 -0.039493   \n",
       "2  0.085299    1  0.044451 -0.005670 -0.045599 -0.034194 -0.032356 -0.002592   \n",
       "3 -0.089063    0 -0.011595 -0.036656  0.012191  0.024991 -0.036038  0.034309   \n",
       "4  0.005383    0 -0.036385  0.021872  0.003935  0.015596  0.008142 -0.002592   \n",
       "\n",
       "         s5        s6  \n",
       "0  0.019907 -0.017646  \n",
       "1 -0.068332 -0.092204  \n",
       "2  0.002861 -0.025930  \n",
       "3  0.022688 -0.009362  \n",
       "4 -0.031988 -0.046641  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace float values in sex by 0/1 binary\n",
    "data.sex = data.sex.apply(lambda x: 1 if x>0 else 0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's split and rescale\n",
    "features = []\n",
    "\n",
    "X = data\n",
    "y = target.to_numpy()\n",
    "X.shape\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to build a Neural Network to perform this regression task. We will build a Neural Networks with 5 hidden layers of 100 units each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_33 (Dense)            (None, 100)               1100      \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 41,601\n",
      "Trainable params: 41,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the Sequential object\n",
    "def regression_mlp(input_dim: tuple[int, ...]) -> Sequential:\n",
    "    # We create a so called Sequential model\n",
    "    model = Sequential()\n",
    "\n",
    "    # Specify the input dimension via an `Input` layer\n",
    "    model.add(Input(input_dim))\n",
    "\n",
    "    # Add the first \"Dense\" layer of 100 units (neurons)\n",
    "    model.add(Dense(100, activation=\"sigmoid\"))\n",
    "    model.add(Dense(100, activation=\"sigmoid\"))\n",
    "    model.add(Dense(100, activation=\"sigmoid\"))\n",
    "    model.add(Dense(100, activation=\"sigmoid\"))\n",
    "    model.add(Dense(100, activation=\"sigmoid\")) \n",
    "\n",
    "    # Add finally the output layer with one unit: the prediction\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    # return the created model\n",
    "    return model\n",
    "\n",
    "mlp = regression_mlp(input_dim=(data.shape[1],))\n",
    "mlp.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compile the model and then fit it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with mean squared error (for regression)\n",
    "mlp.compile(optimizer=\"SGD\", loss=\"mean_squared_error\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 28828.6621 - accuracy: 0.0000e+00 - val_loss: 28605.7422 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 28812.9355 - accuracy: 0.0000e+00 - val_loss: 28605.7422 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 28812.9355 - accuracy: 0.0000e+00 - val_loss: 28605.7422 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 28812.9355 - accuracy: 0.0000e+00 - val_loss: 28605.7422 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 28812.9355 - accuracy: 0.0000e+00 - val_loss: 28605.7422 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 28812.9355 - accuracy: 0.0000e+00 - val_loss: 28605.7422 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 28812.9355 - accuracy: 0.0000e+00 - val_loss: 28605.7422 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 28812.9355 - accuracy: 0.0000e+00 - val_loss: 28605.7422 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 28812.9355 - accuracy: 0.0000e+00 - val_loss: 28605.7422 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 28812.9355 - accuracy: 0.0000e+00 - val_loss: 28605.7422 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 28812.9355 - accuracy: 0.0000e+00 - val_loss: 28605.7422 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 28812.9355 - accuracy: 0.0000e+00 - val_loss: 28605.7422 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 28812.9355 - accuracy: 0.0000e+00 - val_loss: 28605.7422 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 28812.9355 - accuracy: 0.0000e+00 - val_loss: 28605.7422 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 28812.9355 - accuracy: 0.0000e+00 - val_loss: 28605.7422 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 28812.9355 - accuracy: 0.0000e+00 - val_loss: 28605.7422 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 28812.9355 - accuracy: 0.0000e+00 - val_loss: 28605.7422 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 28812.9355 - accuracy: 0.0000e+00 - val_loss: 28605.7422 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 28812.9355 - accuracy: 0.0000e+00 - val_loss: 28605.7422 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 28812.9355 - accuracy: 0.0000e+00 - val_loss: 28605.7422 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 28812.9355 - accuracy: 0.0000e+00 - val_loss: 28605.7422 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 28812.9355 - accuracy: 0.0000e+00 - val_loss: 28605.7422 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 28812.9355 - accuracy: 0.0000e+00 - val_loss: 28605.7422 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 28812.9355 - accuracy: 0.0000e+00 - val_loss: 28605.7422 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 28812.9355 - accuracy: 0.0000e+00 - val_loss: 28605.7422 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 28812.9355 - accuracy: 0.0000e+00 - val_loss: 28605.7422 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 28812.9355 - accuracy: 0.0000e+00 - val_loss: 28605.7422 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 28812.9355 - accuracy: 0.0000e+00 - val_loss: 28605.7422 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 28812.9355 - accuracy: 0.0000e+00 - val_loss: 28605.7422 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 28812.9355 - accuracy: 0.0000e+00 - val_loss: 28605.7422 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 28812.9355 - accuracy: 0.0000e+00 - val_loss: 28605.7422 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 28812.9355 - accuracy: 0.0000e+00 - val_loss: 28605.7422 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 28812.9355 - accuracy: 0.0000e+00 - val_loss: 28605.7422 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 28812.9355 - accuracy: 0.0000e+00 - val_loss: 28605.7422 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 28812.9355 - accuracy: 0.0000e+00 - val_loss: 28605.7422 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 28812.9355 - accuracy: 0.0000e+00 - val_loss: 28605.7422 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 28812.9355 - accuracy: 0.0000e+00 - val_loss: 28605.7422 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 28812.9355 - accuracy: 0.0000e+00 - val_loss: 28605.7422 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 28812.9355 - accuracy: 0.0000e+00 - val_loss: 28605.7422 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 28812.9355 - accuracy: 0.0000e+00 - val_loss: 28605.7422 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 28812.9355 - accuracy: 0.0000e+00 - val_loss: 28605.7422 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 28812.9355 - accuracy: 0.0000e+00 - val_loss: 28605.7422 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 28812.9355 - accuracy: 0.0000e+00 - val_loss: 28605.7422 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 28812.9355 - accuracy: 0.0000e+00 - val_loss: 28605.7422 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 28812.9355 - accuracy: 0.0000e+00 - val_loss: 28605.7422 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 28812.9355 - accuracy: 0.0000e+00 - val_loss: 28605.7422 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 28812.9355 - accuracy: 0.0000e+00 - val_loss: 28605.7422 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 28812.9355 - accuracy: 0.0000e+00 - val_loss: 28605.7422 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 28812.9355 - accuracy: 0.0000e+00 - val_loss: 28605.7422 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 28812.9355 - accuracy: 0.0000e+00 - val_loss: 28605.7422 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe2600e9900>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now fit the model on 500 epoches with a batch size of 64\n",
    "# You can add the test/validation set into the fit: it will give insights on this dataset too\n",
    "mlp.fit(x=X_train, y=y_train, validation_data=(X_test, y_test), epochs=50, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can compute the results of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 3ms/step\n",
      " accurancy sur test: 28605.74157303371\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "y_pred_mlp = mlp.predict(X_test)\n",
    "# MSE\n",
    "mse_test = mean_squared_error(y_test, y_pred_mlp)\n",
    "print(f\" accurancy sur test: {mse_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Benchmarking\n",
    "\n",
    "We can compare that result to a good old linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " accurancy sur test: 3424.259334298692\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression\n",
    "lr = LinearRegression()\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "\n",
    "# MSE linear reg\n",
    "mse_test2 = mean_squared_error(y_test, y_pred_lr)\n",
    "print(f\" accurancy sur test: {mse_test2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course to compare properly the two models, one would make hyperparameter optimization first, this is just for the example."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
