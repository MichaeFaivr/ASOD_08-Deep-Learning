{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit Generation ðŸ”¢\n",
    "\n",
    "![](https://images.unsplash.com/photo-1502570149819-b2260483d302?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=1050&q=80)\n",
    "\n",
    "Photo by [Nick Hillier](https://unsplash.com/photos/yD5rv8_WzxA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A GAN to generate digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, you will be asked to :\n",
    "- complete the code to create your first GAN\n",
    "- train a GAN to generate digits based on the MNIST dataset\n",
    "\n",
    "You should be able to generate new digits by the end of the exercise. This exercise can be run locally, but you can also go for a notebook in Google Colab for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-30T12:24:28.715849Z",
     "start_time": "2019-05-30T12:24:28.706796Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.image as mpimg\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-29T16:33:17.276747Z",
     "start_time": "2019-05-29T16:33:17.272840Z"
    }
   },
   "source": [
    "## I. Input data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this GAN example, we're going to use the MNIST dataset. MNIST is a set of handwritten digits. We'll try to generate new digit samples using GANs.\n",
    "\n",
    "We kindly remind you how to load the data ðŸ™‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-30T12:24:30.426759Z",
     "start_time": "2019-05-30T12:24:29.727444Z"
    }
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Some useful variables\n",
    "img_rows = 28\n",
    "img_cols = 28\n",
    "channels = 1\n",
    "img_shape = (img_rows, img_cols, channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1**. Rescale the data from -1 to 1 and format the X_train dataset in order to have the proper dimensions\n",
    "\n",
    "> ðŸ”¦ **Hint**: Remember, the MNIST dataset is grayscale so contains only one channel but Keras expects input images to have 3 dimensions even if there is only one channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T09:23:37.863536Z",
     "start_time": "2019-12-03T09:23:37.860180Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Rescale -1 to 1 and format the X_train dataset\n",
    "X_train = 2*(X_train/255 - 0.5) #0-1 -0.5 -0.5 +0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## flatten X_train\n",
    "X_train_flat = X_train.reshape(X_train.shape[0], np.prod(X_train.shape[1:]))\n",
    "X_train_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784, 1)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## add the fake channel dim as Keras expects 3 dims\n",
    "X_train_flat = X_train_flat[..., np.newaxis]\n",
    "X_train_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "## also to X_train\n",
    "X_train = X_train[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2**.Visualize one of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T09:23:51.734889Z",
     "start_time": "2019-12-03T09:23:51.730345Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO : Visualize one image\n",
    "def visualize(X_flat):\n",
    "    # Show some reconstructed images\n",
    "    idx = np.random.randint(X_flat.shape[0])\n",
    "\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(X_flat[idx].reshape(28, 28), cmap=plt.cm.gray)\n",
    "    plt.title(\"original image\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "visualize(X_train_flat[:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-29T16:33:17.276747Z",
     "start_time": "2019-05-29T16:33:17.272840Z"
    }
   },
   "source": [
    "## II. Build the GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-30T12:24:31.385068Z",
     "start_time": "2019-05-30T12:24:31.374005Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "###from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import BinaryCrossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. The Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1**. The first step is to build a generator. For the generator, we start with an **input noise shape of size 100**. We then create a sequential model to increase the size of the data up to 1024, before reshaping the data back to the input image shape.\n",
    "\n",
    "Each layer will be made of:\n",
    "- A **Dense layer** (sizes 256, 512, 1024 in order)\n",
    "- A **LeakyRelu activation** with alpha = 0.2\n",
    "- A **Batch normalization** (momentum = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-30T12:24:32.487781Z",
     "start_time": "2019-05-30T12:24:32.468680Z"
    }
   },
   "outputs": [],
   "source": [
    "## VIVADATA non disponible: compliquÃ©\n",
    "## https://stackoverflow.com/questions/34716454/where-do-i-call-the-batchnormalization-function-in-keras\n",
    "\n",
    "## Partie.1: gÃ©nÃ©rateur\n",
    "def build_generator():\n",
    "    # Input Data\n",
    "    noise_shape = (100,)\n",
    "    noise = Input(shape=noise_shape)\n",
    "    \n",
    "    # Create the sequential model\n",
    "    model = Sequential()\n",
    "\n",
    "    ## 3 blocs of Dense, LeakyRelu, BatchNormalization\n",
    "    ## with Dense sizes: 256, 512, 1024 in order\n",
    "\n",
    "    ## ** BLOC.1 **\n",
    "    model.add(Dense(256, input_shape=noise_shape))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "\n",
    "    ## ** BLOC.2 **\n",
    "    model.add(Dense(512, input_shape=noise_shape))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "\n",
    "    ## ** BLOC.3 **\n",
    "    model.add(Dense(1024, input_shape=noise_shape))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    \n",
    "    # Flatten and reshape\n",
    "    model.add(Dense(np.prod(img_shape), activation='tanh'))\n",
    "    model.add(Reshape(img_shape))\n",
    "\n",
    "    # Get result\n",
    "    img = model(noise)\n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    return Model(noise, img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2**. Compile the Generator and add an Adam optimizer as advised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T09:25:18.312334Z",
     "start_time": "2019-12-03T09:25:18.307706Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_42 (Dense)            (None, 256)               25856     \n",
      "                                                                 \n",
      " leaky_re_lu_29 (LeakyReLU)  (None, 256)               0         \n",
      "                                                                 \n",
      " batch_normalization_17 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 512)               131584    \n",
      "                                                                 \n",
      " leaky_re_lu_30 (LeakyReLU)  (None, 512)               0         \n",
      "                                                                 \n",
      " batch_normalization_18 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 1024)              525312    \n",
      "                                                                 \n",
      " leaky_re_lu_31 (LeakyReLU)  (None, 1024)              0         \n",
      "                                                                 \n",
      " batch_normalization_19 (Bat  (None, 1024)             4096      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 784)               803600    \n",
      "                                                                 \n",
      " reshape_7 (Reshape)         (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,493,520\n",
      "Trainable params: 1,489,936\n",
      "Non-trainable params: 3,584\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# TODO : Compile the generator\n",
    "generator = build_generator()\n",
    "generator.compile(optimizer=Adam(learning_rate=0.0003), loss=\"binary_crossentropy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. The Discriminator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3**. Build the discriminator. It takes an input that has the shape of the image. The steps are the following :\n",
    "- Declare the **Sequential** model\n",
    "- **Flatten** the images (with input shape = image shape)\n",
    "- Add a **Dense layer** of 512 and a **Leaky Relu** (0.2)\n",
    "- Add a **Dense layer** of 256 and a **Leaky Relu** (0.2)\n",
    "- Add a **Dense layer** of size 1. What activation function would you use ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-30T12:24:34.899788Z",
     "start_time": "2019-05-30T12:24:34.885304Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_discriminator():\n",
    "    img = Input(shape=img_shape)\n",
    "\n",
    "    # Create the sequential model\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Flatten the images taken as inputs\n",
    "    model.add(Flatten(input_shape=img_shape))\n",
    "\n",
    "    # First layer\n",
    "    model.add(Dense(512))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    # Second layer\n",
    "    model.add(Dense(256))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    # Last layer, return either 0 or 1\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Get model summary\n",
    "    model.summary()\n",
    "\n",
    "    # Get result\n",
    "    validity = model(img)\n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    return Model(img, validity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4**. Now compile the discriminator. (Observe the metric we are using)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T09:25:49.184553Z",
     "start_time": "2019-12-03T09:25:49.180943Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_6 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " leaky_re_lu_32 (LeakyReLU)  (None, 512)               0         \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " leaky_re_lu_33 (LeakyReLU)  (None, 256)               0         \n",
      "                                                                 \n",
      " dense_48 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 533,505\n",
      "Trainable params: 533,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_6 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " leaky_re_lu_32 (LeakyReLU)  (None, 512)               0         \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " leaky_re_lu_33 (LeakyReLU)  (None, 256)               0         \n",
      "                                                                 \n",
      " dense_48 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 533,505\n",
      "Trainable params: 533,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# TODO: Compile the discriminator\n",
    "discriminator = build_discriminator()\n",
    "discriminator.compile(optimizer=Adam(learning_rate=0.0003), loss='mean_squared_error')\n",
    "##   loss_fn=BinaryCrossentropy(from_logits=True))\n",
    "###discriminator.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Build the GAN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q5**. Now it is time to build **the GAN model**. This is done in 4 major steps :\n",
    "- Declare the input\n",
    "- Set the image as the result of the generator of the input\n",
    "- Set the output as the result of the discriminator of the generated image\n",
    "- Define and compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T09:26:11.801129Z",
     "start_time": "2019-12-03T09:26:11.795990Z"
    }
   },
   "outputs": [],
   "source": [
    "### https://stackoverflow.com/questions/47437612/generative-adversarial-networks-gans-in-keras-creating-the-combined-model\n",
    "\n",
    "### https://github.com/zurutech/gans-from-theory-to-production/blob/master/2.%20GANs%20in%20Tensorflow/2.1.%20Writing%20a%20GAN%20from%20scratch.ipynb\n",
    "\n",
    "# 1. Declare input of size (100, )\n",
    "inputShape = (100, )\n",
    "inputTensor = Input(inputShape)\n",
    "\n",
    "# 2. Define the generated image from the input\n",
    "# Hint : Use the generator model compiled above\n",
    "#Getting the output of the generator given our input tensor:\n",
    "genOut = generator(inputTensor) #you call a model just like you call a layer    \n",
    "\n",
    "# 3. Define the output from the image\n",
    "# Hint : Use the discriminator model compiled above\n",
    "#and we pass the generator's output to the discriminator, getting its output:\n",
    "discOut = discriminator(genOut)\n",
    "\n",
    "# For the combined model, only train the generator\n",
    "discriminator.trainable = False\n",
    "\n",
    "# 4.Combined model\n",
    "# Create the model by defining the input and the output\n",
    "GAN_model = Model(inputTensor, discOut)\n",
    "\n",
    "# Once created, we compile the model\n",
    "GAN_model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.0003))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q6**. Print the summary of the new model created. Comment on the shapes at each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T09:26:20.574554Z",
     "start_time": "2019-12-03T09:26:20.569620Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_24 (InputLayer)       [(None, 100)]             0         \n",
      "                                                                 \n",
      " model_17 (Functional)       (None, 28, 28, 1)         1493520   \n",
      "                                                                 \n",
      " model_18 (Functional)       (None, 1)                 533505    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,027,025\n",
      "Trainable params: 1,489,936\n",
      "Non-trainable params: 537,089\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# TODO: Print model summary\n",
    "GAN_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then define a function that is used to save generated images once in a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-30T12:24:41.361699Z",
     "start_time": "2019-05-30T12:24:41.349843Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_imgs(epoch):\n",
    "    \n",
    "    # Predict from input noise\n",
    "    r, c = 5, 5\n",
    "    noise = np.random.normal(0, 1, (r * c, 100))\n",
    "    gen_imgs = generator.predict(noise)\n",
    "\n",
    "    # Rescale images 0 - 1\n",
    "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "    \n",
    "    # Subplots\n",
    "    fig, axs = plt.subplots(r, c)\n",
    "    cnt = 0\n",
    "    \n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
    "            axs[i,j].axis('off')\n",
    "            cnt += 1\n",
    " \n",
    "    fig.savefig(\"images_gan/mnist_%d.png\" % epoch)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we set :\n",
    "- the number of epochs the model will train to 15'000\n",
    "- the batch size to 64\n",
    "- the interval at which we save the images to 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-30T12:28:50.729562Z",
     "start_time": "2019-05-30T12:28:50.722302Z"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 15000\n",
    "batch_size = 64\n",
    "save_interval = 1000\n",
    "half_batch = int(batch_size / 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code is complete. Try to understand the different steps, debug potential errors from your previous code and compile it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the directory to save the images does not exist create it \n",
    "###!mkdir images_gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-30T12:51:49.635827Z",
     "start_time": "2019-05-30T12:33:29.842168Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "half_batch 32\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "(32, 28, 28, 1)\n",
      "d_loss_real: 0.00499789509922266\n",
      "d_loss: 0.08577115880325437\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [129], line 35\u001b[0m\n\u001b[1;32m     32\u001b[0m d_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39madd(d_loss_real, d_loss_fake)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124md_loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00md_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m##scalar\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m d_loss_hist\u001b[38;5;241m.\u001b[39mappend(\u001b[43md_loss\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     36\u001b[0m d_acc\u001b[38;5;241m.\u001b[39mappend(d_loss[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# ---------------------\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m#  Train Generator\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# ---------------------\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# The generator wants the discriminator to label the generated samples as valid (ones)\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "d_loss_hist = []\n",
    "g_loss_hist = []\n",
    "d_acc = []\n",
    "\n",
    "print(f'half_batch {half_batch}')\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # ---------------------\n",
    "    #  Train Discriminator\n",
    "    # ---------------------\n",
    "    \n",
    "    # Pick 50% of sample images\n",
    "    idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
    "    imgs = X_train[idx]\n",
    "\n",
    "    # Generate 50% of new images\n",
    "    noise = np.random.normal(0, 1, (half_batch, 100))\n",
    "    gen_imgs = generator.predict(noise)\n",
    "    \n",
    "    print(imgs.shape) ##(32, 28, 28)\n",
    "    ## half_batch = 32\n",
    "\n",
    "    # Train discriminator on real images with label 1\n",
    "    d_loss_real = discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n",
    "    print(f'd_loss_real: {d_loss_real}') ##scalar\n",
    "    \n",
    "    # Train discriminator on fake images with label 0\n",
    "    d_loss_fake = discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n",
    "    \n",
    "    # Loss of discriminator = Mean of Real and Fake loss\n",
    "    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "    print(f'd_loss: {d_loss}') ##scalar\n",
    "    \n",
    "    d_loss_hist.append(d_loss[0])\n",
    "    d_acc.append(d_loss[1])\n",
    "    \n",
    "    # ---------------------\n",
    "    #  Train Generator\n",
    "    # ---------------------\n",
    "\n",
    "    # The generator wants the discriminator to label the generated samples as valid (ones)\n",
    "    noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "    valid_y = np.array([1] * batch_size)\n",
    "\n",
    "    # Train the generator\n",
    "    g_loss = GAN_model.train_on_batch(noise, valid_y)\n",
    "    g_loss_hist.append(g_loss)\n",
    "    \n",
    "    # Print the progress\n",
    "    print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "        \n",
    "    if epoch % save_interval == 0:\n",
    "        save_imgs(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Create new samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q7**. We now have all the elements required to generate new samples. What are according to you :\n",
    "- the steps to generate new samples ?\n",
    "- the part of the network we re-use ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q8**. You are now asked to generate and visualize new samples from the steps you defined above. Pay attention when plotting generated images to :\n",
    "- rescale the images between 0 and 1 (as done previously)\n",
    "- reshape the generated image to 28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T09:26:43.879292Z",
     "start_time": "2019-12-03T09:26:43.875424Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Visualize a generated image"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
